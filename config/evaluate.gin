import conversational_ai.tasks

include "eval.gin"

utils.run.mode = "eval"
utils.run.dataset_split = "validation"

utils.run.eval_checkpoint_step = "all"

# utils.run.batch_size = ("tokens_per_replica", 32768)  # set by eval.gin
# utils.run.batch_size = ("tokens_per_batch", 16384)
utils.run.batch_size = ("tokens_per_replica", 16384)

# Setting this lower makes decodes faster
Bitransformer.decode.max_decode_length = 128
