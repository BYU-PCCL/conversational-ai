task_name/macro.value = "conversation_v001_compounding"

finetune.mixture_or_task_name = %task_name
# finetune.pretrained_model_dir = "gs://t5-data/pretrained_models/large"
finetune.pretrained_model_dir = "./checkpoints/large"
finetune.steps = 10_000

evaluate.mixture_or_task_name = %task_name
# evaluate.steps = -1
evaluate.steps = "all"

MtfModel.model_dir = "./checkpoints/t5"
MtfModel.batch_size = ("tokens_per_batch", 2048)
MtfModel.sequence_length = {"inputs": 512, "targets": 256}
MtfModel.learning_rate_schedule = 0.001
# MtfModel.model_parallelism = 1
MtfModel.mesh_devices = ["gpu:0"]
MtfModel.mesh_shape = "model:1,batch:1"
MtfModel.tpu = None
MtfModel.tpu_topology = None
MtfModel.keep_checkpoint_max = 5
MtfModel.save_checkpoints_steps = 500
